<!doctype html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="../../icons/logoTit.png">
    <link rel="stylesheet" href="../../estilo.css">
    <title>UB Social</title>
</head>
<body>
<div class="container-fluid">


    <div class="row">
        <div class="col-sm-12">
            <nav class="navbar rounded-bottom fixed-top navbar-expand-lg navbar-light bg-light shadow">
                <div class="container-fluid">
                    <a class="navbar-brand" href="../../index.html"><img src="../../icons/logo.png" class="d-inline-block align-text-top" width="11pt"> UB Social</a>
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                    <div class="collapse navbar-collapse" id="navbarNav">
                        <ul class="navbar-nav">
                            <li class="nav-item"><a class="nav-link" href="../../index.html">Home</a></li>
                            <li class="nav-item"><a class="nav-link" href="../../sobre/sobre.html">Sobre</a></li>
                            <li class="nav-item"><a class="nav-link" href="../../livros/livros.html">Livros</a></li>
                        </ul>
                    </div>
                </div>
            </nav>
        </div>
    </div>

    <div class="row">
        <div class="col-sm-12 text-center" id="titulo">
            <h1>CS50AI Harvard</h1>
            <h6><strong>Arquivos e projetos do curso CS50AI 2024</strong></h6>
            <a href="../../index.html" class="btn btn-link text-decoration-none mb-3">Voltar</a><br>
            <a href="" class="btn btn-link disabled text-decoration-none" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="1.3em" height="1.3em" fill="currentColor" class="bi bi-youtube text-danger" viewBox="0 0 16 16"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.007 2.007 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.007 2.007 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31.4 31.4 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.007 2.007 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A99.788 99.788 0 0 1 7.858 2h.193zM6.4 5.209v4.818l4.157-2.408L6.4 5.209z"/></svg> Conteúdo disponível</a><br>
			<a href="https://github.com/mateusschwede/cs50ai_2024" class="btn btn-link text-decoration-none" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-github text-dark" viewBox="0 0 16 16"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 8.01 0 0 0 16 8c0-4.42-3.58-8-8-8"/></svg> Github do projeto</a>
        </div>

        <div class="col-sm-12">
            <h4>Sumário:</h4>
            <ol start="0">
                <li><a href="#search" class="text-decoration-none">Search</a></li>
                <li><a href="#knowledge" class="text-decoration-none">Knowledge</a></li>
            </ol>

            <br><hr><h4 id="search">0.Search:</h4>
            <p id="textoPost">Problemas de busca envolvem agente (agent) que recebe estado (state) inicial e estado objetivo, retornando solução de como ir do 1º para o último. Um app de navegação usa processo de busca típico, onde agente (parte pensante do programa) recebe como entrada sua localização atual e destino desejado, e, com base no algoritmo de busca, retorna caminho sugerido. No entanto, existem muitas outras formas de problemas de busca, como quebra-cabeças e labirintos.</p>
            <img src="0.search/search1.png" class="img-fluid rounded" width="100px">
            <p id="textoPost">Encontrando solução para quebra-cabeça de 15 exigiria uso de um algoritmo de busca.</p>
            <ul>
                <li><b>Agent</b>: entidade que percebe seu ambiente e age sobre esse. No app de navegação, agente seria uma representação do carro que precisa decidir quais ações tomar para chegar ao destino;</li>
                <li><b>State</b>: Configuração de agente no ambiente. Exemplo, <a href="https://en.wikipedia.org/wiki/15_puzzle" target="_blank" class="text-decoration-none">quebra-cabeça de 15</a>, estado é qualquer maneira que todos nªs são organizados no tabuleiro;
                    <ul>
                        <li><b>Initial State</b>: estado a partir do qual algoritmo de busca inicia. No app de navegação, esse seria a localização atual.</li>
                    </ul>
                </li>
                <li><b>Actions</b>: escolhas que podem ser feitas no estado. Ações podem ser definidas como função. Ao receber estado 's' como entrada, 'action(s)' retorna, como saída, conjunto de ações que podem ser executadas no estado 's'. Exemplo, quebra-cabeça de 15, ações de determinado estado são as maneiras que você pode deslizar quadrados na configuração atual (4 se o quadrado vazio estiver no meio, 3 se próximo a um lado, 2 se no canto);</li>
                <li><b>Transition Model</b>: descrição de qual estado resulta da execução de qualquer ação aplicável em qualquer estado. Modelo de transição pode ser definido como função. Ao receber estado 's' e ação 'a' como entrada, 'results(s, a)' retorna estado resultante da execução da ação 'a' no estado 's'. Exemplo, dada configuração de quebra-cabeça de 15 (estado s), mover quadrado em qualquer direção (ação a) levará a nova configuração do quebra-cabeça (novo estado);</li>
                <li><b>State Space</b>: conjunto de todos estados alcançáveis a partir do estado inicial por qualquer sequência de ações. Exemplo, quebra-cabeça de 15, espaço de estados consiste em todas as 16!/2 configurações no tabuleiro, que podem ser alcançadas a partir de qualquer estado inicial. Espaço de estados pode ser visualizado como gráfico direcionado com estados, representados como nós (nodes), e ações, representadas como setas entre nós;
                    <br><img src="0.search/search2.png" class="img-fluid rounded" width="400px">
                </li>
                <li><b>Goal Test</b>: condição que determina se estado é estado objetivo. Exemplo, app de navegação, teste objetivo seria se localização atual do agente (carro) está no destino. Se estiver, problema resolvido. Se não estiver, continua-se busca;</li>
                <li><b>Path Cost</b>: custo numérico associado a determinado caminho. Exemplo, app de navegação não leva simplesmente ao objetivo; ele faz isso minimizando custo do caminho, encontrando caminho mais rápido possível para chegar ao estado de objetivo.</li>
                <img src="0.search/search7.png" class="img-fluid rounded" width="300px">
            </ul>

            <br><h5>Solucionando problemas de busca:</h5>
            <p id="textoPost">Solução é sequência de ações que leva do estado inicial ao estado objetivo. Solução otimizada possui menor custo de caminho entre todas soluções. No processo de busca, dados geralmente são armazenados em nó, estrutura que contém os seguintes dados:</p>
            <ul>
                <li>Estado (state);</li>
                <li>Seu nó pai (parent node), através do qual o nó atual foi gerado;</li>
                <li>Ação que foi aplicada ao estado do pai para chegar ao nó atual;</li>
                <li>Custo do caminho do estado inicial até este nó.</li>
            </ul>
            <p id="textoPost">Nós contêm informações que os tornam úteis para propósitos de algoritmos de busca. Contêm estado, que pode ser verificado via teste de meta, verificando se é estado final. Se for, custo do caminho do nó pode ser comparado aos demais, permitindo escolher solução otimizada. Após nó escolhido, através do armazenamento do nó pai e da ação que levou do pai ao nó atual, é possível rastrear cada passo do caminho do estado inicial até este nó, sequência de ações denominada solução. Contudo, nós são apenas estrutura de dados, que não pesquisam, somente guardam informações. Para pesquisa, usa-se fronteira (frontier), mecanismo que "gerencia" nós. Fronteira inicia com estado inicial e conjunto vazio de itens explorados, e então repete as seguintes ações até que uma solução seja alcançada:</p>
            <ol>
                <li>Se fronteira está vazia, então pare. Não há solução para o problema;</li>
                <li>Remova 1 nó da fronteira. Este nó que será considerado;</li>
                <li>Se nó conter estado objetivo, então retorne a solução e pare. Senão, expanda o nó (encontre todos novos nós que podem ser alcançados a partir deste) e adicione nós resultantes à fronteira. Adicione nó atual ao conjunto explorado.</li>
            </ol>
            <img src="0.search/search8.png" class="img-fluid rounded" width="350px">
            <img src="0.search/search9.png" class="img-fluid rounded" width="350px"><br>

            <br><h5>Busca em profundidade:</h5>
            <p id="textoPost">No passo 2 do conteúdo acima, qual nó deve ser removido? Essa escolha tem implicações na qualidade da solução e rapidez com que ela é alcançada. Há várias maneiras de abordar tal questão, 2 das quais podem ser representadas pelas estruturas de dados de pilha (stack, via busca em profundidade) e fila (queue, via busca em largura). Algoritmo de busca em profundidade (depth-first search - DFS) esgota cada direção antes de tentar outra. Assim, a fronteira é gerenciada como estrutura de pilha (LIFO). Após nós adicionados à fronteira, 1º nó a ser removido e considerado é último a ser adicionado. Isso resulta em algoritmo de busca que vai o mais fundo possível na 1ª direção que atrapalha, enquanto deixa todas as outras para depois. Imagine você procurando suas chaves: Na busca em profundidade, se você escolher começar procurando nas calças, você passaria por cada bolso, esvaziando-os e examinando-os. Você parará de procurar nas calças e começará procurar em outro lugar somente quando tiver esgotado completamente a busca em cada bolso das calças.</p>
            <ul>
                <li>Prós: na melhor das hipóteses, algoritmo é mais rápido. Se "tiver sorte" e sempre escolher caminho certo para solução (por acaso), então busca em profundidade leva menor tempo possível para chegar a solução;</li>
                <li>Contras: possibilidade da solução encontrada não ser a ideal. Na pior das hipóteses, algoritmo explorará todos caminhos possíveis antes de encontrar a solução, levando maior tempo possível antes de chegar à solução.</li>
            </ul>
            <p>Código exemplo de DFS:</p>
<small><pre><code>
# Definir função que remove nó da fronteira e o retorna
def remove(self):
    # Encerrar busca se fronteira estiver vazia, pois significa que não há solução
    if self.empty():
        raise Exception("fronteira vazia")
    else:
        # Salvar último item da lista (nó mais novo adicionado)
        node = self.frontier[-1]
        # Salvar todos itens da lista além do último nó (remover último nó)
        self.frontier = self.frontier[:-1]
        return node
</code></pre></small>
            <img src="0.search/search10.png" class="img-fluid rounded" width="350px">
            <img src="0.search/search12.png" class="img-fluid rounded" width="350px"><br>

            <br><h5>Busca em largura:</h5>
            <p id="textoPost">Oposto da DFS, algoritmo de busca em largura (breadth-first search - BFS) seguirá várias direções ao mesmo tempo, dando 1 passo em cada direção possível antes de dar 2º passo em cada direção. Nele, fronteira é gerenciada como estrutura de dados de queue (FIFO). Todos novos nós são somados em linha, onde são considerados com base em qual foi adicionado 1º (1º a chegar, 1º a ser considerado), resultando em algoritmo de busca, que dá 1 passo em cada direção possível antes de dar 2º passo em qualquer direção. Imagine você procurando suas chaves: Se começar pelas calças, olhará no bolso direito. Após, em vez de olhar no bolso esquerdo, olhará na gaveta, depois na mesa, etc. Somente após ter esgotado todos lugares, você voltará para calças e procurará no próximo bolso.</p>
            <ul>
                <li>Prós: garantia de encontrar ótima solução;</li>
                <li>Contras: geralmente, algoritmo levará mais tempo de execução. Na pior das hipóteses, algoritmo levará maior tempo possível de execução.</li>
            </ul>
            <p>Código exemplo BFS:</p>
<small><pre><code>
# Definir função que remove nó da fronteira e o retorna
def remove(self):
    # Encerrar busca se fronteira estiver vazia, pois significa que não há solução
    if self.empty():
        raise Exception("empty frontier")
    else:
        # Salvar item mais antigo da lista (1ª adicionado)
        node = self.frontier[0]
        # Salvar todos itens da lista além do 1º nó (remover 1º nó)
        self.frontier = self.frontier[1:]
        return node
</code></pre></small>
            <img src="0.search/search11.png" class="img-fluid rounded" width="350px">
            <img src="0.search/search13.png" class="img-fluid rounded" width="350px"><br>

            <br><h5>Busca gananciosa do melhor 1º:</h5>
            <p id="textoPost">Algoritmos de busca em largura e em profundidade são desinformados, não obtendo conhecimento extra do problema, além dos adquiridos por meio da própria exploração. Geralmente, há conhecimentos extras sobre o mesmo. Exemplo, quando solucionador de labirinto humano entra em junção, humano e IA distinguem qual caminho vai na direção geral da solução e qual não vai. Algoritmo de busca informado obtém conhecimento extra para tentar melhorar desempenho. Busca gananciosa do melhor 1º (Greedy best-first search) expande nó que está mais próximo do objetivo, via função heurística h(n). Tal função estima quão próximo do objetivo o próximo nó está, podendo estar enganada. Eficiência do algoritmo depende do quão eficiente é tal função. Exemplo: labirinto, algoritmo pode usar função heurística, dependente da distância de Manhattan entre nós possíveis e fim do labirinto. Distância de Manhattan ignora paredes e conta quantos passos para cima, baixo ou lados, são necessários para ir de local até destino. Esta estimativa pode ser derivada com base em coordenadas (x,y) do local atual e destino.</p>
            <img src="0.search/search3.png" class="img-fluid rounded" width="300px">
            <img src="0.search/search14.png" class="img-fluid rounded" width="300px">
            <p id="textoPost">Contudo, heurística pode errar, levando algoritmo em caminho mais lento do que usual. É possível que algoritmo de busca desinformado forneça solução melhor mais rápido, mas menos provável que faça isso do que algoritmo informado.</p>

            <br><h5>A* Search:</h5>
            <p id="textoPost">Busca A* considera não apenas h(n), custo estimado do local atual até destino, mas também g(n), custo acumulado até local atual. Combinando esses 2 valores, algoritmo é mais preciso determinando custo da solução e otimizando escolhas em andamento. Algoritmo mantém controle de (custo do caminho até agora + custo estimado até destino) e, ao exceder custo estimado de alguma opção anterior, algoritmo abandonará caminho atual e retorna à opção anterior, evitando seguir por caminho longo e ineficiente que h(n) erroneamente marcou como melhor. Algoritmo depende de heurística, sendo tão bom quanto heurística empregada, sendo possível situações de menor eficiência do que busca gananciosa do melhor 1º ou algoritmos desinformados. Função heurística eficiente deve ser:</p>
            <ol>
                <li>Admissível, ou nunca superestimar custo real;</li>
                <li>Consistente, onde custo estimado do caminho para destino de novo nó, além do custo de transição para ele a partir do nó anterior, é maior ou igual ao custo estimado do caminho para destino do nó anterior. Portanto, h(n) é consistente se para cada nó n e nó sucessor n' com custo de passo c, h(n) ≤p h(n') + c.</li>
            </ol>
            <img src="0.search/search15.png" class="img-fluid rounded" width="300px"><br>

            <br><h5>Busca adversária:</h5>
            <p id="textoPost">Enquanto, anteriormente, algoritmos precisam encontrar resposta para pergunta, na busca adversarial (adversarial search) algoritmo enfrenta oponente que tenta atingir objetivo oposto. Geralmente encontrada em games.</p>

            <br><h5>Minimax:</h5>
            <p id="textoPost">Algoritmo de busca adversarial, representando condições vencedoras como (-1) para lado e (+1) para outro. Devido tais condições, lado minimizador tenta obter pontuação mais baixa, e maximizador tenta obter pontuação mais alta. IA representando jogo da velha:</p>
            <ul>
                <li>S₀: estado inicial (nesse caso, tabuleiro 3X3 vazio);</li>
                <li>Jogador(es): função que, dado estado s, retorna vez de qual jogador é (X ou O);</li>
                <li>Ação(s): função que, dado estado s, retorna todos movimentos legais neste estado (quais espaços estão livres no tabuleiro);</li>
                <li>Resultado(s,a): função que, dado estado s e ação a, retorna novo estado. Tabuleiro que resultou da execução da ação a no estado s (fazer movimento no jogo);</li>
                <li>Terminal(s): função que, dado estado s, verifica se este é último passo do jogo, ou seja, se alguém ganhou ou empate. Retorna True se jogo terminou, False caso contrário;</li>
                <li>Utilidade(s): função que, dado estado terminal s, retorna valor de utilidade do estado: -1, 0 ou 1.</li>
            </ul>
            <p id="textoPost">Recursivamente, algoritmo simula todos jogos possíveis que podem ocorrer no estado atual e até que um estado terminal seja alcançado. Cada estado terminal é avaliado como (-1), 0 ou (+1).</p>
            <img src="0.search/search4.png" class="img-fluid rounded" width="500px">
            <p id="textoPost">Com base no estado de quem é a vez, algoritmo pode saber se jogador atual, ao jogar de forma otimizada, escolherá ação que leva a estado com valor menor ou maior. Então, alternando entre minimizar e maximizar, algoritmo cria valores para estado que resultariam de cada ação possível. Supõe-se que ogador maximizador pergunta cada turno: "se eu tomar essa ação, um novo estado resultará. Se jogador minimizador jogar de forma otimizada, que ação esse jogador pode tomar para levar ao menor valor?" Contudo, para responder, jogador maximizador pergunta: "Para saber o que jogador minimizador fará, preciso simular mesmo processo na mente do minimizador: jogador minimizador tentará perguntar: 'se eu tomar essa ação, que ação jogador maximizador pode tomar para levar ao maior valor?'". Eventualmente, por meio desse processo de raciocínio recursivo, jogador maximizador gera valores para cada estado, resultantes de todas ações possíveis no estado atual. Após ter esses valores, jogador maximizador escolhe valor mais alto.</p>
            <img src="0.search/search5.png" class="img-fluid rounded" width="200px">
            <p id="textoPost">Maximizador considera valores possíveis de estados futuros. Minimax funciona assim:</p>
            <ul>
                <li>Dado estado s;
                    <ul>
                        <li>Jogador maximizador escolhe ação a em ação(s) que produz maior valor de Min-Value(Result(s,a));</li>
                        <li>Jogador que minimiza escolhe ação a em Ações(s) que produz menor valor de Max-Value(Result(s,a)).</li>
                    </ul>
                </li>
                <li>Função Max-Value(estado);
                    <ul>
                        <li>v = -∞;</li>
                        <li>Se Terminal(estado): retorna Utilidade(estado);</li>
                        <li>Para ação em Ações(estado): v = Max(v, Min-Value(Result(estado,ação))) e retorna v.</li>
                    </ul>
                </li>
                <li>Função Min-Value(estado);
                    <ul>
                        <li>v = ∞;</li>
                        <li>Se Terminal(estado): retorna Utilidade(estado);</li>
                        <li>Para ação em Ações(estado): v = Min(v, Max-Value(Result(estado,ação))) e retorna v.</li>
                    </ul>
                </li>
            </ul>

            <br><h5>Poda Alfa-Beta:</h5>
            <p id="textoPost">Otimizando Minimax, Alpha-Beta Pruning pula cálculos recursivos desfavoráveis. Após estabelecer valor de ação, se houver evidência inicial de que ação seguinte pode levar oponente a obter pontuação melhor do que ação já estabelecida, não há necessidade de investigar mais, pois será menos favorável do que anterior. Exemplo: jogador maximizador sabe que, na próxima etapa, jogador minimizador tentará atingir pontuação mais baixa. Suponha que jogador maximizador tenha 3 ações possíveis, a 1ª vale 4. Então jogador começa a gerar valor para próxima ação. Para isso, jogador gera valores das ações do minimizador, se jogador atual fizer essa ação, sabendo que minimizador escolherá a mais baixa. Contudo, antes de terminar cálculo para todas ações possíveis do minimizador, jogador encontra opção de valor 3. Isso significa que não há razão para continuar explorando as outras ações possíveis para jogador minimizador. Valor da ação ainda não valorizada não importa, seja 10 ou (-10). Se valor for 10, minimizador escolherá opção mais baixa, 3, que já é pior do que 4 preestabelecido. Se ação ainda não valorizada for (-10), minimizador escolherá tal opção, ainda mais desfavorável ao maximizador. Computar ações possíveis adicionais para minimizador neste ponto é irrelevante para maximizador, pois já tem-se escolha inequivocamente melhor de valor 4.</p>
            <img src="0.search/search6.png" class="img-fluid rounded" width="300px"><br>

            <br><h5>Minimax com profundidade limitada:</h5>
            <p id="textoPost">Há total de 255.168 jogadas possíveis de Jogo da Velha, e 10²⁹⁰⁰⁰ jogadas possíveis no Xadrez. Minimax requer geração de todas jogadas hipotéticas de certo ponto até condição terminal. Embora computar todas jogadas de Jogo da Velha não represente desafio para computador, no xadrez é atualmente impossível. Minimax com profundidade limitada (Depth-limited Minimax) considera apenas nª predefinido de movimentos antes de parar, nunca alcançando estado terminal. Porém, isso não permite obter valor preciso para cada ação, uma vez que fim dos jogos hipotéticos não foi alcançado. Para isso, Minimax com profundidade limitada depende de função de avaliação que estima utilidade esperada do jogo, atribuindo valores aos estados. Exemplo: jogo de xadrez, função de utilidade recebe entrada a configuração atual do tabuleiro, tentando avaliar utilidade esperada (com base nas peças que cada jogador tem e localizações no tabuleiro) e, em seguida, retornaria valor positivo ou negativo que representa quão favorável o tabuleiro é para jogador em relação ao outro. Tais valores podem ser usados para decidir sobre ação correta e, quanto melhor função de avaliação, melhor seu algoritmo Minimax.</p>

            <br><h5>Quiz:</h5>
            <ol>
                <li>Entre busca em profundidade (DFS) e busca em largura (BFS), qual encontrará caminho mais curto em labirinto?
                    <ul>
                        <li>A DFS sempre encontrará caminho mais curto que BFS;</li>
                        <li>A BFS sempre encontrará caminho mais curto que DFS;</li>
                        <li>A DFS às vezes, mas nem sempre, encontrará caminho mais curto que BFS;</li>
                        <li>A BFS às vezes, mas nem sempre, encontrará caminho mais curto que DFS;</li>
                        <li>Ambos algoritmos sempre encontrarão caminhos do mesmo comprimento.</li>
                        <li><b>Resposta</b>: BFS às vezes, mas nem sempre, encontrará caminho mais curto que DFS.</li>
                    </ul>
                </li>
                <li>Considere labirinto abaixo. Células cinzas indicam paredes. Algoritmo de busca foi executado neste labirinto e encontrou caminho destacado em amarelo do ponto A ao B. Ao fazer isso, células destacadas em vermelho eram estados explorados, mas que não levaram ao objetivo.
                    <br><img src="0.search/quiz0.png" class="img-fluid rounded" width="250px">
                    <br>Dos 4 algoritmos de busca - busca em profundidade, busca em largura, busca gananciosa do melhor 1º com heurística de distância de Manhattan e busca A* com heurística de distância de Manhattan - qual deles (ou vários, se vários forem possíveis) poderia ser algoritmo usado?
                    <ul>
                        <li>Só poderia ser A*;</li>
                        <li>Só poderia ser pesquisa gananciosa do melhor 1º;</li>
                        <li>Só poderia ser DFS;</li>
                        <li>Só poderia ser BFS;</li>
                        <li>Só poderia ser A* ou pesquisa gananciosa do melhor 1º;</li>
                        <li>Só poderia ser DFS ou BFS;</li>
                        <li>Só poderia ser qualquer um dos 4 algoritmos;</li>
                        <li>Não poderia ser nenhum dos 4 algoritmos.</li>
                        <li><b>Resposta</b>: Só poderia ser DFS.</li>
                    </ul>
                </li>
                <li>Por que Minimax com profundidade limitada às vezes é preferível ao Minimax sem limite de profundidade?
                    <ul>
                        <li>Minimax com profundidade limitada pode chegar a decisão mais rapidamente porque explora menos estados;</li>
                        <li>Minimax com profundidade limitada atingirá a mesma saída que Minimax sem limite de profundidade, mas às vezes pode usar menos memória;</li>
                        <li>Minimax com profundidade limitada pode tomar decisão mais otimizada ao não explorar estados conhecidos por serem subótimos;</li>
                        <li>Minimax com profundidade limitada nunca é preferível ao Minimax sem limite de profundidade.</li>
                        <li><b>Resposta</b>: Minimax com profundidade limitada pode chegar a decisão mais rapidamente porque explora menos estados.</li>
                    </ul>
                </li>
                <li>Considere árvore Minimax abaixo, onde setas verdes para cima indicam jogador MAX e setas vermelhas para baixo indicam jogador MIN. Os nós folha são cada um rotulados com seu valor.
                    <br><img src="0.search/quiz1.png" class="img-fluid rounded" width="250px">
                    <br>Qual o valor do nó raiz?
                    <ul>
                        <li><b>Resposta</b>: 5.</li>
                    </ul>
                </li>
            </ol>

            <br><h5>Código fonte:</h5>
            <p>maze.py:</p>
<small><pre><code>
import sys

class Node():
    def __init__(self, state, parent, action):
        self.state = state
        self.parent = parent
        self.action = action


class StackFrontier():
    def __init__(self):
        self.frontier = []

    def add(self, node):
        self.frontier.append(node)

    def contains_state(self, state):
        return any(node.state == state for node in self.frontier)

    def empty(self):
        return len(self.frontier) == 0

    def remove(self):
        if self.empty():
            raise Exception("empty frontier")
        else:
            node = self.frontier[-1]
            self.frontier = self.frontier[:-1]
            return node


class QueueFrontier(StackFrontier):

    def remove(self):
        if self.empty():
            raise Exception("empty frontier")
        else:
            node = self.frontier[0]
            self.frontier = self.frontier[1:]
            return node

class Maze():

    def __init__(self, filename):

        # Read file and set height and width of maze
        with open(filename) as f:
            contents = f.read()

        # Validate start and goal
        if contents.count("A") != 1:
            raise Exception("maze must have exactly one start point")
        if contents.count("B") != 1:
            raise Exception("maze must have exactly one goal")

        # Determine height and width of maze
        contents = contents.splitlines()
        self.height = len(contents)
        self.width = max(len(line) for line in contents)

        # Keep track of walls
        self.walls = []
        for i in range(self.height):
            row = []
            for j in range(self.width):
                try:
                    if contents[i][j] == "A":
                        self.start = (i, j)
                        row.append(False)
                    elif contents[i][j] == "B":
                        self.goal = (i, j)
                        row.append(False)
                    elif contents[i][j] == " ":
                        row.append(False)
                    else:
                        row.append(True)
                except IndexError:
                    row.append(False)
            self.walls.append(row)

        self.solution = None


    def print(self):
        solution = self.solution[1] if self.solution is not None else None
        print()
        for i, row in enumerate(self.walls):
            for j, col in enumerate(row):
                if col:
                    print("█", end="")
                elif (i, j) == self.start:
                    print("A", end="")
                elif (i, j) == self.goal:
                    print("B", end="")
                elif solution is not None and (i, j) in solution:
                    print("*", end="")
                else:
                    print(" ", end="")
            print()
        print()


    def neighbors(self, state):
        row, col = state
        candidates = [
            ("up", (row - 1, col)),
            ("down", (row + 1, col)),
            ("left", (row, col - 1)),
            ("right", (row, col + 1))
        ]

        result = []
        for action, (r, c) in candidates:
            if 0 &lt;= r &lt; self.height and 0 &lt;= c &lt; self.width and not self.walls[r][c]:
                result.append((action, (r, c)))
        return result


    def solve(self):
        """Finds a solution to maze, if one exists."""

        # Keep track of number of states explored
        self.num_explored = 0

        # Initialize frontier to just the starting position
        start = Node(state=self.start, parent=None, action=None)
        frontier = StackFrontier()
        frontier.add(start)

        # Initialize an empty explored set
        self.explored = set()

        # Keep looping until solution found
        while True:

            # If nothing left in frontier, then no path
            if frontier.empty():
                raise Exception("no solution")

            # Choose a node from the frontier
            node = frontier.remove()
            self.num_explored += 1

            # If node is the goal, then we have a solution
            if node.state == self.goal:
                actions = []
                cells = []
                while node.parent is not None:
                    actions.append(node.action)
                    cells.append(node.state)
                    node = node.parent
                actions.reverse()
                cells.reverse()
                self.solution = (actions, cells)
                return

            # Mark node as explored
            self.explored.add(node.state)

            # Add neighbors to frontier
            for action, state in self.neighbors(node.state):
                if not frontier.contains_state(state) and state not in self.explored:
                    child = Node(state=state, parent=node, action=action)
                    frontier.add(child)


    def output_image(self, filename, show_solution=True, show_explored=False):
        from PIL import Image, ImageDraw
        cell_size = 50
        cell_border = 2

        # Create a blank canvas
        img = Image.new(
            "RGBA",
            (self.width * cell_size, self.height * cell_size),
            "black"
        )
        draw = ImageDraw.Draw(img)

        solution = self.solution[1] if self.solution is not None else None
        for i, row in enumerate(self.walls):
            for j, col in enumerate(row):

                # Walls
                if col:
                    fill = (40, 40, 40)

                # Start
                elif (i, j) == self.start:
                    fill = (255, 0, 0)

                # Goal
                elif (i, j) == self.goal:
                    fill = (0, 171, 28)

                # Solution
                elif solution is not None and show_solution and (i, j) in solution:
                    fill = (220, 235, 113)

                # Explored
                elif solution is not None and show_explored and (i, j) in self.explored:
                    fill = (212, 97, 85)

                # Empty cell
                else:
                    fill = (237, 240, 252)

                # Draw cell
                draw.rectangle(
                    ([(j * cell_size + cell_border, i * cell_size + cell_border),
                      ((j + 1) * cell_size - cell_border, (i + 1) * cell_size - cell_border)]),
                    fill=fill
                )

        img.save(filename)


if len(sys.argv) != 2:
    sys.exit("Usage: python maze.py maze.txt")

m = Maze(sys.argv[1])
print("Maze:")
m.print()
print("Solving...")
m.solve()
print("States Explored:", m.num_explored)
print("Solution:")
m.print()
m.output_image("maze.png", show_explored=True)
</code></pre></small>
            <p>maze1.txt:</p>
<small><pre><code>
#####B#
##### #
####  #
#### ##
     ##
A######
</code></pre></small>
            <p>maze2.txt:</p>
<small><pre><code>
###                 #########
#   ###################   # #
# ####                # # # #
# ################### # # # #
#                     # # # #
##################### # # # #
#   ##                # # # #
# # ## ### ## ######### # # #
# #    #   ##B#         # # #
# # ## ################ # # #
### ##             #### # # #
### ############## ## # # # #
###             ##    # # # #
###### ######## ####### # # #
###### ####             #   #
A      ######################
</code></pre></small>
            <p>maze3.txt:</p>
<small><pre><code>
##    #
## ## #
#B #  #
# ## ##
     ##
A######
</code></pre></small>
            <p>requirements.txt:</p>
<small><pre><code>
pillow
</code></pre></small>

            <br><h5>Projeto Degrees:</h5>
<small><pre><code>
import csv
import sys
from collections import deque

names = &#123;&#125;
people = &#123;&#125;
movies = &#123;&#125;


def load_data(directory):
    with open(f"&#123;directory&#125;/people.csv", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            person_id = row["id"]
            people[person_id] = &#123;
                "name": row["name"],
                "birth": row["birth"],
                "movies": set()
            &#125;
            if row["name"].lower() not in names:
                names[row["name"].lower()] = &#123;person_id&#125;
            else:
                names[row["name"].lower()].add(person_id)

    with open(f"&#123;directory&#125;/movies.csv", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            movie_id = row["id"]
            movies[movie_id] = &#123;
                "title": row["title"],
                "year": row["year"],
                "stars": set()
            &#125;

    with open(f"&#123;directory&#125;/stars.csv", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            try:
                people[row["person_id"]]["movies"].add(row["movie_id"])
                movies[row["movie_id"]]["stars"].add(row["person_id"])
            except KeyError:
                pass


def main():
    if len(sys.argv) &gt; 2:
        sys.exit("Usage: python degrees.py [directory]")
    directory = sys.argv[1] if len(sys.argv) == 2 else "large"

    print("Loading data...")
    load_data(directory)
    print("Data loaded.")

    source = person_id_for_name(input("Name: "))
    if source is None:
        sys.exit("Person not found.")
    target = person_id_for_name(input("Name: "))
    if target is None:
        sys.exit("Person not found.")

    path = shortest_path(source, target)

    if path is None:
        print("Not connected.")
    else:
        degrees = len(path)
        print(f"&#123;degrees&#125; degrees of separation.")
        path = [(None, source)] + path
        for i in range(degrees):
            person1 = people[path[i][1]]["name"]
            person2 = people[path[i + 1][1]]["name"]
            movie = movies[path[i + 1][0]]["title"]
            print(f"&#123;i + 1&#125;: &#123;person1&#125; and &#123;person2&#125; starred in &#123;movie&#125;")


def shortest_path(source, target):
    start = Node(state=source, parent=None, action=None)
    frontier = deque([start])
    explored = set()

    while frontier:
        node = frontier.popleft()

        if node.state == target:
            path = []
            while node.parent is not None:
                path.append((node.action, node.state))
                node = node.parent
            path.reverse()
            return path

        explored.add(node.state)

        for action, state in neighbors_for_person(node.state):
            if state not in explored and not any(n.state == state for n in frontier):
                child = Node(state=state, parent=node, action=action)
                frontier.append(child)

    return None


def person_id_for_name(name):
    person_ids = list(names.get(name.lower(), set()))
    if len(person_ids) == 0:
        return None
    elif len(person_ids) &gt; 1:
        print(f"Which '&#123;name&#125;'?")
        for i, person_id in enumerate(person_ids):
            person = people[person_id]
            print(f" &#123;i + 1&#125;. &#123;person['name']&#125; (born &#123;person['birth']&#125;)")
        try:
            index = int(input("Intended Person: ")) - 1
            if 0 &lt;= index &lt; len(person_ids):
                return person_ids[index]
        except ValueError:
            pass
        return None
    else:
        return person_ids[0]


def neighbors_for_person(person_id):
    movie_ids = people[person_id]["movies"]
    neighbors = set()
    for movie_id in movie_ids:
        for person_id in movies[movie_id]["stars"]:
            neighbors.add((movie_id, person_id))
    return neighbors


class Node:
    def __init__(self, state, parent, action):
        self.state = state
        self.parent = parent
        self.action = action

    def __eq__(self, other):
        return isinstance(other, Node) and self.state == other.state

    def __hash__(self):
        return hash(self.state)
</code></pre></small>
            <br><h5>Projeto Tic-Tac-Toe:</h5>
            <p>errors.py:</p>
<small><pre><code>
class Error(Exception):
    pass


class InvalidActionError(Error):
    def __init__(self, action, board, message):
        print('InvalidActionError: ', message, 'Action: ', action, 'on board: ', board)
</code></pre></small>
            <p>runner.py:</p>
<small><pre><code>
import pygame
import sys
import time

import tictactoe as ttt

pygame.init()
size = width, height = 600, 400

# Colors
black = (0, 0, 0)
white = (255, 255, 255)

screen = pygame.display.set_mode(size)

mediumFont = pygame.font.Font("OpenSans-Regular.ttf", 28)
largeFont = pygame.font.Font("OpenSans-Regular.ttf", 40)
moveFont = pygame.font.Font("OpenSans-Regular.ttf", 60)

user = None
board = ttt.initial_state()
ai_turn = False

while True:

    for event in pygame.event.get():
        if event.type == pygame.QUIT:
            sys.exit()

    screen.fill(black)

    # Let user choose a player.
    if user is None:

        # Draw title
        title = largeFont.render("Play Tic-Tac-Toe", True, white)
        titleRect = title.get_rect()
        titleRect.center = ((width / 2), 50)
        screen.blit(title, titleRect)

        # Draw buttons
        playXButton = pygame.Rect((width / 8), (height / 2), width / 4, 50)
        playX = mediumFont.render("Play as X", True, black)
        playXRect = playX.get_rect()
        playXRect.center = playXButton.center
        pygame.draw.rect(screen, white, playXButton)
        screen.blit(playX, playXRect)

        playOButton = pygame.Rect(5 * (width / 8), (height / 2), width / 4, 50)
        playO = mediumFont.render("Play as O", True, black)
        playORect = playO.get_rect()
        playORect.center = playOButton.center
        pygame.draw.rect(screen, white, playOButton)
        screen.blit(playO, playORect)

        # Check if button is clicked
        click, _, _ = pygame.mouse.get_pressed()
        if click == 1:
            mouse = pygame.mouse.get_pos()
            if playXButton.collidepoint(mouse):
                time.sleep(0.2)
                user = ttt.X
            elif playOButton.collidepoint(mouse):
                time.sleep(0.2)
                user = ttt.O

    else:

        # Draw game board
        tile_size = 80
        tile_origin = (width / 2 - (1.5 * tile_size),
                       height / 2 - (1.5 * tile_size))
        tiles = []
        for i in range(3):
            row = []
            for j in range(3):
                rect = pygame.Rect(
                    tile_origin[0] + j * tile_size,
                    tile_origin[1] + i * tile_size,
                    tile_size, tile_size
                )
                pygame.draw.rect(screen, white, rect, 3)

                if board[i][j] != ttt.EMPTY:
                    move = moveFont.render(board[i][j], True, white)
                    moveRect = move.get_rect()
                    moveRect.center = rect.center
                    screen.blit(move, moveRect)
                row.append(rect)
            tiles.append(row)

        game_over = ttt.terminal(board)
        player = ttt.player(board)

        # Show title
        if game_over:
            winner = ttt.winner(board)
            if winner is None:
                title = f"Game Over: Tie."
            else:
                title = f"Game Over: &#123;winner&#125; wins."
        elif user == player:
            title = f"Play as &#123;user&#125;"
        else:
            title = f"Computer thinking..."
        title = largeFont.render(title, True, white)
        titleRect = title.get_rect()
        titleRect.center = ((width / 2), 30)
        screen.blit(title, titleRect)

        # Check for AI move
        if user != player and not game_over:
            if ai_turn:
                time.sleep(0.5)
                move = ttt.minimax(board)
                board = ttt.result(board, move)
                ai_turn = False
            else:
                ai_turn = True

        # Check for a user move
        click, _, _ = pygame.mouse.get_pressed()
        if click == 1 and user == player and not game_over:
            mouse = pygame.mouse.get_pos()
            for i in range(3):
                for j in range(3):
                    if (board[i][j] == ttt.EMPTY and tiles[i][j].collidepoint(mouse)):
                        board = ttt.result(board, (i, j))

        if game_over:
            againButton = pygame.Rect(width / 3, height - 65, width / 3, 50)
            again = mediumFont.render("Play Again", True, black)
            againRect = again.get_rect()
            againRect.center = againButton.center
            pygame.draw.rect(screen, white, againButton)
            screen.blit(again, againRect)
            click, _, _ = pygame.mouse.get_pressed()
            if click == 1:
                mouse = pygame.mouse.get_pos()
                if againButton.collidepoint(mouse):
                    time.sleep(0.2)
                    user = None
                    board = ttt.initial_state()
                    ai_turn = False

    pygame.display.flip()
</code></pre></small>
            <p>tictactoe.py:</p>
<small><pre><code>
import random
from errors import InvalidActionError
from copy import deepcopy

X = "X"
O = "O"
EMPTY = None


def initial_state():
    return [[EMPTY, EMPTY, EMPTY],
            [EMPTY, EMPTY, EMPTY],
            [EMPTY, EMPTY, EMPTY]]


def player(board):
    countX = 0
    countO = 0
    countEMPTY = 0

    for r in board:
        countX = countX + r.count(X)
        countO = countO + r.count(O)
        countEMPTY = countEMPTY + r.count(EMPTY)

    if countX &gt; countO:
        return O
    else:
        return X


def actions(board):
    move = set()

    for i in range(3):
        for j in range(3):
            if board[i][j] == EMPTY:
                move.add((i, j))
    return move


def result(board, action):
    i = action[0]
    j = action[1]

    if i not in [0, 1, 2] or j not in [0, 1, 2]:
        raise InvalidActionError(action, board, 'Invalid board position for action')
    elif board[i][j] is not EMPTY:
        raise InvalidActionError(action, board, 'Invalid action on occupaied tile')

    copyBoard = deepcopy(board)
    copyBoard[i][j] = player(board)
    return copyBoard


def winner(board):

    for r in board:
        if r.count(X) == 3:
            return X
        if r.count(O) == 3:
            return O

    for j in range(3):
        column = ''
        for i in range(3):
            column = column + str(board[i][j])

        if column == 'XXX':
            return X
        elif column == 'OOO':
            return O

    d1 = ''
    d2 = ''
    j = 2

    for i in range(3):
        d1 = d1 + str(board[i][i])
        d2 = d2 + str(board[i][j])
        j = j - 1

    if d1 == 'XXX' or d2 == 'XXX':
        return X
    elif d1 == 'OOO' or d2 == 'OOO':
        return O
    return None


def terminal(board):
    if winner(board) or not actions(board):
        return True
    else:
        return False


def utility(board):
    if winner(board) == 'X':
        return 1
    elif winner(board) == 'O':
        return -1
    else:
        return 0


exploredActions = 0


def minimax(board):
    global exploredActions
    exploredActions = 0

    def max_player(board, bMin=10):
        global exploredActions

        if terminal(board):
            return (utility(board), None)

        value = -10
        bAction = None
        actionSet = actions(board)

        while len(actionSet) &gt; 0:
            action = random.choice(tuple(actionSet))
            actionSet.remove(action)

            if bMin &lt;= value:
                break

            exploredActions = exploredActions + 1
            min_player_result = min_player(result(board, action), value)
            
            if min_player_result[0] &gt; value:
                bAction = action
                value = min_player_result[0]
        return (value, bAction)

    def min_player(board, bMax=-10):
        global exploredActions

        if terminal(board):
            return (utility(board), None)

        value = 10
        bAction = None
        actionSet = actions(board)

        while len(actionSet) &gt; 0:
            action = random.choice(tuple(actionSet))
            actionSet.remove(action)

            if bMax &gt;= value:
                break

            exploredActions = exploredActions + 1
            max_player_result = max_player(result(board, action), value)
        
            if max_player_result[0] &lt; value:
                bAction = action
                value = max_player_result[0]
        return (value, bAction)

    if terminal(board):
        return None

    if player(board) == 'X':
        print('AI is working')
        bMove = max_player(board)[1]
        print('AI actions: ', exploredActions)
        return bMove
    else:
        print('AI is working')
        bMove = min_player(board)[1]
        print('AI actions: ', exploredActions)
        return bMove
</code></pre></small>

            <br><hr><h4 id="knowledge">1.Conhecimento:</h4>
            <p class="text-muted">Conteúdo em breve.</p>
        </div>
    </div>


<!--Rodapé-->
<div class="row">
    <div class="col-sm-12 text-center bg-black text-light pt-4 pb-3">
        <p>Elaborado por Mateus Schwede<br><small class="text-muted">ubsocial.github.io</small></p>
    </div>
</div>

</div>
</body>
</html>